{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2edaab89",
   "metadata": {},
   "source": [
    "# Two-Pane Refactor Automation (Binder retained)\n",
    "\n",
    "This notebook automates applying refactor steps while retaining the user-facing term \"Binder\". It syncs with GitHub, discovers files, runs guarded transforms, formats/lints, tests, bumps version, and pushes changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "179024c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': '3.11.6 (tags/v3.11.6:8b6ee5b, Oct  2 2023, 14:57:12) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'repo_path': 'c:\\\\Python Projects\\\\NoteBook_clean', 'target_branch': 'main', 'force': False, 'python_exec': 'c:\\\\Python Projects\\\\NoteBook_clean\\\\.venv\\\\Scripts\\\\python.exe'}\n",
      "git: git version 2.50.1.windows.1\n",
      "WARN: python not found: Command 'c:\\Python Projects\\NoteBook_clean\\.venv\\Scripts\\python.exe --version' returned non-zero exit status 1.\n",
      "Installing GitPython...\n",
      "Toolchain ready.\n",
      "Toolchain ready.\n"
     ]
    }
   ],
   "source": [
    "# 1. Set Up Environment and Load Repo Settings\n",
    "import os, sys, json, subprocess, platform\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurable env\n",
    "REPO_PATH = Path(os.getenv(\"REPO_PATH\", Path.cwd()))\n",
    "TARGET_BRANCH = os.getenv(\"TARGET_BRANCH\", \"main\")\n",
    "FORCE = os.getenv(\"FORCE\", \"0\") == \"1\"\n",
    "IGNORE_GLOBS = os.getenv(\"IGNORE_GLOBS\", \".venv|.git|__pycache__|dist|build\").split(\"|\")\n",
    "SEVERITY_THRESHOLD = os.getenv(\"SEVERITY_THRESHOLD\", \"error\")\n",
    "\n",
    "# Use project venv python if available\n",
    "VENV_PY = REPO_PATH / \".venv\" / \"Scripts\" / \"python.exe\"\n",
    "if VENV_PY.exists():\n",
    "    PYTHON = str(VENV_PY)\n",
    "else:\n",
    "    PYTHON = sys.executable\n",
    "\n",
    "print({\n",
    "    \"python\": sys.version,\n",
    "    \"platform\": platform.platform(),\n",
    "    \"repo_path\": str(REPO_PATH),\n",
    "    \"target_branch\": TARGET_BRANCH,\n",
    "    \"force\": FORCE,\n",
    "    \"python_exec\": PYTHON,\n",
    "})\n",
    "\n",
    "# Ensure tools installed\n",
    "REQS = [\n",
    "    (\"git\", \"git --version\"),\n",
    "    (\"python\", f\"{PYTHON} --version\"),\n",
    "]\n",
    "for name, cmd in REQS:\n",
    "    try:\n",
    "        out = subprocess.check_output(cmd, shell=True, text=True).strip()\n",
    "        print(f\"{name}: {out}\")\n",
    "    except Exception as e:\n",
    "        print(f\"WARN: {name} not found: {e}\")\n",
    "\n",
    "# Pip packages\n",
    "PKGS = [\"GitPython\", \"toml\", \"ruamel.yaml\", \"pytest\", \"coverage\", \"black\", \"isort\", \"ruff\", \"mypy\", \"bandit\", \"safety\"]\n",
    "for p in PKGS:\n",
    "    try:\n",
    "        __import__(p.replace(\"-\", \"_\"))\n",
    "    except Exception:\n",
    "        print(f\"Installing {p}...\")\n",
    "        subprocess.check_call([PYTHON, \"-m\", \"pip\", \"install\", p])\n",
    "\n",
    "print(\"Toolchain ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "476d5c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overrides set: {'DRY_RUN': False, 'FORCE': True}\n"
     ]
    }
   ],
   "source": [
    "# Helper: enforce settings for write-enabled run and allow sync to proceed\n",
    "DRY_RUN = False\n",
    "FORCE = True\n",
    "print(\"Overrides set:\", {\"DRY_RUN\": DRY_RUN, \"FORCE\": FORCE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07671e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TARGET_BRANCH': 'refactor/two-pane'}\n"
     ]
    }
   ],
   "source": [
    "# 1b. Target feature branch for refactor work\n",
    "FEATURE_BRANCH = os.getenv(\"FEATURE_BRANCH\", \"refactor/two-pane\")\n",
    "TARGET_BRANCH = FEATURE_BRANCH\n",
    "print({\"TARGET_BRANCH\": TARGET_BRANCH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0e82af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch refactor/two-pane, based on main\n"
     ]
    }
   ],
   "source": [
    "# 2. Sync From GitHub (Feature Branch)\n",
    "from git import Repo, GitCommandError\n",
    "\n",
    "repo = Repo(str(REPO_PATH))\n",
    "assert not repo.bare, \"Repo not found or bare\"\n",
    "\n",
    "# Local changes check\n",
    "if repo.is_dirty(untracked_files=True) and not FORCE:\n",
    "    raise SystemExit(\"Local changes present. Commit/stash or set FORCE=1 to proceed.\")\n",
    "\n",
    "origin = repo.remotes.origin if hasattr(repo.remotes, 'origin') else repo.create_remote('origin', url='origin')\n",
    "try:\n",
    "    # Ensure feature branch based on main\n",
    "    base_branch = os.getenv(\"BASE_BRANCH\", \"main\")\n",
    "    repo.git.checkout(base_branch)\n",
    "    origin.fetch()\n",
    "    repo.git.pull('origin', base_branch)\n",
    "    # Create/switch to feature branch\n",
    "    if FEATURE_BRANCH in repo.branches:\n",
    "        repo.git.checkout(FEATURE_BRANCH)\n",
    "        repo.git.rebase(base_branch)\n",
    "    else:\n",
    "        repo.git.checkout('-b', FEATURE_BRANCH)\n",
    "    print(f\"On branch {FEATURE_BRANCH}, based on {base_branch}\")\n",
    "except GitCommandError as e:\n",
    "    raise SystemExit(f\"Git sync failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e409dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 283 candidate files.\n",
      "Sample:\n",
      " - db_access.py\n",
      " - db_pages.py\n",
      " - db_sections.py\n",
      " - db_version.py\n",
      " - import.py\n",
      " - inspect_db.py\n",
      " - inspect_sections.py\n",
      " - main.py\n",
      " - media_store.py\n",
      " - pyproject.toml\n",
      " - README.md\n",
      " - RefactorPlan.ipynb\n",
      " - sample_spreadsheet.py\n",
      " - settings.json\n",
      " - settings_manager.py\n",
      " - ui_loader.py\n",
      " - ui_logic.py\n",
      " - ui_richtext.py\n",
      " - ui_sections.py\n",
      " - ui_tabs.py\n"
     ]
    }
   ],
   "source": [
    "# 3. Discover Project Files to Modify\n",
    "from pathlib import Path\n",
    "import fnmatch\n",
    "\n",
    "root = REPO_PATH\n",
    "candidates = []\n",
    "EXTS = {\".py\", \".ipynb\", \".md\", \".yaml\", \".yml\", \".toml\", \".json\"}\n",
    "\n",
    "ignored = [p.strip() for p in IGNORE_GLOBS if p.strip()]\n",
    "\n",
    "def _ignored(path: Path) -> bool:\n",
    "    parts = set(path.parts)\n",
    "    if any(part in {\".git\", \"__pycache__\"} for part in parts):\n",
    "        return True\n",
    "    s = str(path)\n",
    "    for pat in ignored:\n",
    "        if pat and pat in s:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for p in root.rglob('*'):\n",
    "    if p.is_file() and p.suffix.lower() in EXTS and not _ignored(p):\n",
    "        candidates.append(p)\n",
    "\n",
    "print(f\"Found {len(candidates)} candidate files.\")\n",
    "print(\"Sample:\")\n",
    "for p in candidates[:20]:\n",
    "    print(\" -\", p.relative_to(root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57acee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforms ready. Dry run: True\n"
     ]
    }
   ],
   "source": [
    "# 4. Define Safe Transformations (Skip Any 'Binder' Renames)\n",
    "import re\n",
    "from difflib import unified_diff\n",
    "\n",
    "# Prefer in-notebook DRY_RUN flag; fallback to env\n",
    "try:\n",
    "    dry_run = bool(DRY_RUN)\n",
    "except NameError:\n",
    "    import os as _os\n",
    "    dry_run = _os.getenv(\"DRY_RUN\", \"1\") == \"1\"\n",
    "\n",
    "# Example transform rules (add more as needed)\n",
    "def to_fstrings(text: str) -> str:\n",
    "    # Minimal example: replace str.format with f-strings where trivial\n",
    "    return text  # placeholder no-op\n",
    "\n",
    "def standardize_logging(text: str) -> str:\n",
    "    return text  # stub: add real rules later\n",
    "\n",
    "TRANSFORMS = [to_fstrings, standardize_logging]\n",
    "\n",
    "BINDER_GUARD = re.compile(r\"\\b[Bb]inder\\b\")\n",
    "\n",
    "def apply_transforms(path: Path, text: str) -> str:\n",
    "    original = text\n",
    "    for fn in TRANSFORMS:\n",
    "        text = fn(text)\n",
    "    # Guard: if diff would alter any line containing Binder tokens, skip\n",
    "    if BINDER_GUARD.search(original) or BINDER_GUARD.search(text):\n",
    "        if original != text:\n",
    "            diff = list(unified_diff(original.splitlines(True), text.splitlines(True)))\n",
    "            if any(BINDER_GUARD.search(line) for line in diff):\n",
    "                return original\n",
    "    return text\n",
    "\n",
    "print(\"Transforms ready. Dry run:\", dry_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0d6fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report:\n",
      "{\n",
      "  \"changed\": [],\n",
      "  \"skipped\": [\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\db_access.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\db_pages.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\db_sections.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\db_version.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\import.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\inspect_db.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\inspect_sections.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\main.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\media_store.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\README.md\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\sample_spreadsheet.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\settings.json\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\settings_manager.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\ui_loader.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\ui_logic.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\ui_richtext.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\ui_sections.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\ui_tabs.py\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\.vscode\\\\extensions.json\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\.vscode\\\\launch.json\",\n",
      "    \"c:\\\\Python Projects\\\\NoteBook_clean\\\\.vscode\\\\tasks.json\"\n",
      "  ],\n",
      "  \"errors\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 5. Apply Transformations With Backups and Diffs\n",
    "from difflib import unified_diff\n",
    "import json\n",
    "\n",
    "report = {\"changed\": [], \"skipped\": [], \"errors\": []}\n",
    "\n",
    "INCLUDE = [g.strip() for g in os.getenv(\"INCLUDE_GLOBS\", \"\").split(\",\") if g.strip()]\n",
    "EXCLUDE = [g.strip() for g in os.getenv(\"EXCLUDE_GLOBS\", \"\").split(\",\") if g.strip()]\n",
    "\n",
    "def matched(path: Path, globs):\n",
    "    s = str(path)\n",
    "    return any(fnmatch.fnmatch(s, g) for g in globs)\n",
    "\n",
    "for path in candidates:\n",
    "    try:\n",
    "        if INCLUDE and not matched(path, INCLUDE):\n",
    "            continue\n",
    "        if EXCLUDE and matched(path, EXCLUDE):\n",
    "            continue\n",
    "        if path.suffix.lower() not in {\".py\", \".md\", \".yaml\", \".yml\", \".toml\", \".json\"}:\n",
    "            continue\n",
    "        text = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        new_text = apply_transforms(path, text)\n",
    "        if new_text != text:\n",
    "            print(f\"\\n--- {path} \\n\")\n",
    "            diff = \"\".join(unified_diff(text.splitlines(True), new_text.splitlines(True), fromfile=str(path), tofile=str(path)))\n",
    "            print(diff)\n",
    "            if not dry_run:\n",
    "                bak = path.with_suffix(path.suffix + \".bak\")\n",
    "                bak.write_text(text, encoding=\"utf-8\")\n",
    "                path.write_text(new_text, encoding=\"utf-8\")\n",
    "                report[\"changed\"].append(str(path))\n",
    "        else:\n",
    "            report[\"skipped\"].append(str(path))\n",
    "    except Exception as e:\n",
    "        report[\"errors\"].append({\"file\": str(path), \"error\": str(e)})\n",
    "\n",
    "print(\"\\nReport:\")\n",
    "print(json.dumps(report, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb603fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tooling config updated.\n"
     ]
    }
   ],
   "source": [
    "# 6. Update Tooling Config (pyproject.toml, linters, CI)\n",
    "import toml\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "def _safe_load_toml(path: Path):\n",
    "    data = {}\n",
    "    if path.exists():\n",
    "        try:\n",
    "            data = toml.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return data\n",
    "\n",
    "def _safe_dump_toml(path: Path, data: dict):\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    tmp.write_text(toml.dumps(data), encoding=\"utf-8\")\n",
    "    tmp.replace(path)\n",
    "\n",
    "pyproj = REPO_PATH / \"pyproject.toml\"\n",
    "proj = _safe_load_toml(pyproj)\n",
    "proj.setdefault(\"tool\", {}).setdefault(\"black\", {\"line-length\": 100})\n",
    "proj[\"tool\"].setdefault(\"isort\", {\"profile\": \"black\"})\n",
    "proj[\"tool\"].setdefault(\"ruff\", {\"line-length\": 100})\n",
    "proj[\"tool\"].setdefault(\"mypy\", {\"ignore_missing_imports\": True})\n",
    "_safe_dump_toml(pyproj, proj)\n",
    "\n",
    "# Minimal CI YAML touch (idempotent)\n",
    "yaml = YAML()\n",
    "ci_path = REPO_PATH / \".github\" / \"workflows\" / \"ci.yml\"\n",
    "ci = {}\n",
    "if ci_path.exists():\n",
    "    try:\n",
    "        ci = yaml.load(ci_path.read_text(encoding=\"utf-8\")) or {}\n",
    "    except Exception:\n",
    "        ci = {}\n",
    "ci.setdefault(\"name\", \"CI\")\n",
    "ci.setdefault(\"on\", [\"push\", \"pull_request\"])  # minimal\n",
    "jobs = ci.setdefault(\"jobs\", {})\n",
    "jobs.setdefault(\"lint\", {\"runs-on\": \"ubuntu-latest\", \"steps\": [{\"uses\": \"actions/checkout@v4\"}, {\"run\": \"pip install black isort ruff && ruff . && black --check . && isort --check-only .\"}]})\n",
    "jobs.setdefault(\"test\", {\"runs-on\": \"ubuntu-latest\", \"steps\": [{\"uses\": \"actions/checkout@v4\"}, {\"run\": \"pip install -r requirements.txt pytest && pytest -q\"}]})\n",
    "ci_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "yaml.dump(ci, ci_path.open(\"w\", encoding=\"utf-8\"))\n",
    "print(\"Tooling config updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f5c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m black --check .\n",
      "Running: c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m isort --check-only .\n",
      "Running: c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m ruff check --exit-zero .\n",
      "Lint summary: {'black': 1, 'isort': 1, 'ruff': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error executing c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m black --check .: [WinError 2] The system cannot find the file specified\n",
      "Error executing c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m isort --check-only .: [WinError 2] The system cannot find the file specified\n",
      "Error executing c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m ruff check --exit-zero .: [WinError 2] The system cannot find the file specified\n"
     ]
    }
   ],
   "source": [
    "# 7. Format (check-only) and Lint\n",
    "import subprocess, sys, shlex\n",
    "\n",
    "# Use project venv python when available\n",
    "try:\n",
    "    PYTHON\n",
    "except NameError:\n",
    "    from pathlib import Path as _Path\n",
    "    _venv = _Path.cwd() / \".venv\" / \"Scripts\" / \"python.exe\"\n",
    "    PYTHON = str(_venv) if _venv.exists() else sys.executable\n",
    "\n",
    "def run_cmd(cmd: str) -> int:\n",
    "    print(\"Running:\", cmd)\n",
    "    try:\n",
    "        result = subprocess.run(shlex.split(cmd), capture_output=True, text=True)\n",
    "        if result.stdout:\n",
    "            print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(result.stderr, file=sys.stderr)\n",
    "        return result.returncode\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing {cmd}: {e}\", file=sys.stderr)\n",
    "        return 1\n",
    "\n",
    "BLACK = f\"{PYTHON} -m black {'--check' if dry_run else ''} .\".strip()\n",
    "ISORT = f\"{PYTHON} -m isort {'--check-only' if dry_run else ''} .\".strip()\n",
    "RUFF = f\"{PYTHON} -m ruff {'check --exit-zero' if dry_run else 'check'} .\".strip()\n",
    "\n",
    "rc_black = run_cmd(BLACK)\n",
    "rc_isort = run_cmd(ISORT)\n",
    "rc_ruff = run_cmd(RUFF)\n",
    "\n",
    "print(\"Lint summary:\", {\"black\": rc_black, \"isort\": rc_isort, \"ruff\": rc_ruff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94fa329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytest rc: 5\n"
     ]
    }
   ],
   "source": [
    "# 8. Run Unit Tests and Coverage\n",
    "import sys, subprocess\n",
    "\n",
    "try:\n",
    "    PYTHON\n",
    "except NameError:\n",
    "    from pathlib import Path as _Path\n",
    "    _venv = _Path.cwd() / \".venv\" / \"Scripts\" / \"python.exe\"\n",
    "    PYTHON = str(_venv) if _venv.exists() else sys.executable\n",
    "\n",
    "cmd = f\"{PYTHON} -m pytest -q --maxfail=1\"\n",
    "rc = subprocess.call(cmd, shell=True)\n",
    "print(\"pytest rc:\", rc)\n",
    "\n",
    "# Coverage summary if available\n",
    "cov_xml = REPO_PATH / \"coverage.xml\"\n",
    "if cov_xml.exists():\n",
    "    import xml.etree.ElementTree as ET\n",
    "    root = ET.parse(str(cov_xml)).getroot()\n",
    "    summaries = root.findall('.//coverage')\n",
    "    print(\"coverage summaries:\", summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f720493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m mypy .\n",
      "Running: c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m bandit -q -r .\n",
      "Running: c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m safety check --full-report\n",
      "Checks summary: {'mypy': 1, 'bandit': 1, 'safety': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error executing c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m mypy .: [WinError 2] The system cannot find the file specified\n",
      "Error executing c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m bandit -q -r .: [WinError 2] The system cannot find the file specified\n",
      "Error executing c:\\Users\\donal\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m safety check --full-report: [WinError 2] The system cannot find the file specified\n"
     ]
    }
   ],
   "source": [
    "# 9. Type and Security checks\n",
    "import subprocess, sys, shlex\n",
    "\n",
    "try:\n",
    "    PYTHON\n",
    "except NameError:\n",
    "    from pathlib import Path as _Path\n",
    "    _venv = _Path.cwd() / \".venv\" / \"Scripts\" / \"python.exe\"\n",
    "    PYTHON = str(_venv) if _venv.exists() else sys.executable\n",
    "\n",
    "def run_cmd(cmd: str) -> int:\n",
    "    print(\"Running:\", cmd)\n",
    "    try:\n",
    "        result = subprocess.run(shlex.split(cmd), capture_output=True, text=True)\n",
    "        if result.stdout:\n",
    "            print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(result.stderr, file=sys.stderr)\n",
    "        return result.returncode\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing {cmd}: {e}\", file=sys.stderr)\n",
    "        return 1\n",
    "\n",
    "MYPY = f\"{PYTHON} -m mypy .\"\n",
    "BANDIT = f\"{PYTHON} -m bandit -q -r .\"\n",
    "SAFETY = f\"{PYTHON} -m safety check --full-report\"\n",
    "\n",
    "rc_mypy = run_cmd(MYPY)\n",
    "rc_bandit = run_cmd(BANDIT)\n",
    "rc_safety = run_cmd(SAFETY)\n",
    "\n",
    "print(\"Checks summary:\", {\"mypy\": rc_mypy, \"bandit\": rc_bandit, \"safety\": rc_safety})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aad0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Bump Version and Update Changelog\n",
    "import datetime\n",
    "\n",
    "def bump_version_in_pyproject(pyproj: Path):\n",
    "    data = _safe_load_toml(pyproj)\n",
    "    tool_poetry = data.setdefault(\"tool\", {}).setdefault(\"poetry\", {})\n",
    "    ver = tool_poetry.get(\"version\") or data.setdefault(\"project\", {}).get(\"version\")\n",
    "    if not ver:\n",
    "        return None\n",
    "    parts = ver.split('.')\n",
    "    parts[-1] = str(int(parts[-1]) + 1)\n",
    "    new_ver = '.'.join(parts)\n",
    "    if \"version\" in tool_poetry:\n",
    "        tool_poetry[\"version\"] = new_ver\n",
    "    else:\n",
    "        data.setdefault(\"project\", {})[\"version\"] = new_ver\n",
    "    _safe_dump_toml(pyproj, data)\n",
    "    return new_ver\n",
    "\n",
    "new_ver = bump_version_in_pyproject(pyproj)\n",
    "print(\"New version:\", new_ver)\n",
    "\n",
    "# Basic changelog from git log\n",
    "log = subprocess.check_output([\"git\", \"log\", \"--pretty=format:%h %s\", \"-n\", \"20\"], cwd=str(REPO_PATH), text=True)\n",
    "changelog_path = REPO_PATH / \"CHANGELOG.md\"\n",
    "ts = datetime.datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "entry = f\"\\n\\n## {new_ver or 'Unreleased'} - {ts}\\n\" + '\\n'.join(f\"- {line}\" for line in log.splitlines())\n",
    "with changelog_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(entry)\n",
    "print(\"Changelog updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9931f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10b. Tag current main as stable (optional, idempotent)\n",
    "try:\n",
    "    from git import Repo\n",
    "    repo = Repo(str(REPO_PATH))\n",
    "    base_branch = os.getenv(\"BASE_BRANCH\", \"main\")\n",
    "    tag_name = os.getenv(\"STABLE_TAG\", f\"stable-{__import__('datetime').datetime.utcnow().strftime('%Y%m%d')}\")\n",
    "    # Only create tag if it doesn't exist\n",
    "    if tag_name not in [t.name for t in repo.tags]:\n",
    "        cur = repo.git.rev_parse(f\"origin/{base_branch}\")\n",
    "        repo.create_tag(tag_name, cur, message=f\"Stable snapshot of {base_branch}\")\n",
    "        print(f\"Created tag {tag_name} at {cur}\")\n",
    "    else:\n",
    "        print(f\"Tag {tag_name} already exists; skipping\")\n",
    "except Exception as e:\n",
    "    print(\"WARN: Could not create stable tag:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c937192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Commit, Tag, and Push to GitHub (Feature Branch)\n",
    "from git import Repo\n",
    "\n",
    "repo = Repo(str(REPO_PATH))\n",
    "repo.git.add(A=True)\n",
    "msg = \"chore(refactor): two-pane groundwork (guarded transforms, tooling updates, Binder retained)\"\n",
    "if 'new_ver' in globals() and new_ver:\n",
    "    msg += f\"\\n\\nBump version to {new_ver}\"\n",
    "repo.index.commit(msg)\n",
    "if 'new_ver' in globals() and new_ver:\n",
    "    # tag release on feature branch too (optional)\n",
    "    tag_name = f\"v{new_ver}\"\n",
    "    if tag_name not in [t.name for t in repo.tags]:\n",
    "        repo.create_tag(tag_name, message=f\"Release {new_ver}\")\n",
    "repo.remotes.origin.push()\n",
    "# Push feature branch explicitly\n",
    "repo.remotes.origin.push(refspec=f\"HEAD:{FEATURE_BRANCH}\")\n",
    "# Push tags if any\n",
    "if 'new_ver' in globals() and new_ver:\n",
    "    repo.remotes.origin.push(tags=True)\n",
    "print(\"Pushed changes. HEAD:\", repo.head.commit.hexsha, \"branch:\", FEATURE_BRANCH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
